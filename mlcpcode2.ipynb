{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5297eee7-7ae8-4ec4-bc86-7a63b906ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "#from pyodide.ffi import to_js\n",
    "import pickle\n",
    "import math\n",
    "from scipy.spatial.distance import cdist\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from pymatgen.core.structure import Structure, Lattice, IStructure\n",
    "from pymatgen.io.xyz import XYZ\n",
    "from pymatgen.analysis.local_env import VoronoiNN\n",
    "from pymatgen.core import periodic_table as PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88327cf6-7c66-49b2-b6fa-80f5042f5ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#files=['CaFe4Sb12.cif','1601417.cif','Clathrate-I.cif',#'EntryWithCollCode17347.cif',#@'2129946.cif',\n",
    "# %'Cu.cif','Cu7PS6.cif','Ag8SnSe6.cif','EntryWithCollCode80292.cif',#'EntryWithCollCode25.cif',\n",
    "# 'EntryWithCollCode137778.cif',#'EntryWithCollCode280375.cif','SnSe_optimized.cif','InTe.cif',\n",
    "# 'Co9S8.cif', 'CoS2.cif', 'CoSi.cif', 'CuFeS2.cif', 'TiS2.cif','TiS2.cif','VFeSb.cif',\n",
    "# #'Li2Ge11Sb2Te15.cif', 'YbCd2Sb2.cif', #'Ge12Sb2Te15.cif', #'Ag2Se.cif', 'MgAgSb.cif',\n",
    "# 'Sb2Si2Te6.cif', #'Li2Ge3Sb2Te7.cif', 'Tl4SnTe3.cif', 'Bi2Te3.cif', 'LiCoO2.cif','GeTe.cif',\n",
    "# #'FeVSb.cif', 'CoGeTe.cif', 'YbSi2.cif', #'NbCoSn.cif', #'Ag8SiSe6_off.cif', #'Yb9Ca4BaMgSb11_off.cif',\n",
    "# 'Cu12Sb4S13.cif', #'As2Te2Se.cif', 'BaBiTe3.cif', @'LaCoO3.cif', #'Eu2ZnSb2.cif',\n",
    "# #'Cu11ZnSb4S13.cif']\n",
    "#restrictions: no partial occupancies#, no particular elements like La @, more than one element %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de48575d-be9e-4b50-a8f2-de6eb862537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#line inputs:\n",
    "\n",
    "#file being used\n",
    "cif='CaFe4Sb12.cif'\n",
    "#scale factor\n",
    "sf=1.0\n",
    "#template\n",
    "temp=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc87449-95c6-4d85-8c08-9daeed9d5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check contacts within this distance\n",
    "radius = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b92600c-9831-4019-bbc8-a01eb15ca0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modifile(filename, action, lines=None):\n",
    "    # Reads, writes, or appends a file\n",
    "    if action == \"r\":\n",
    "        with open(filename, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "        return lines\n",
    "    else:\n",
    "        if lines is not None:\n",
    "            with open(filename, action) as file:\n",
    "                file.writelines(lines)\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfcd8206-0176-4d45-b756-bf0dd1449826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modifile(\"cif.cif\", \"w\", cif)\n",
    "df2 = modifile(\"./element_data.txt\", \"r\")\n",
    "for i in range(len(df2)):\n",
    "    df2[i] = [float(j) for j in df2[i].split(\"\\t\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fbd8eb3-2383-448b-aeee-522ce2bd76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = Structure.from_file(cif)\n",
    "#scales\n",
    "structure.scale_lattice(structure.volume*(float(sf)**3))\n",
    "#some rounding, making things 0-1\n",
    "for i in range(len(structure)):\n",
    "    c = structure[i].frac_coords\n",
    "    for j in range(3):\n",
    "        if c[j] > -1e-5 and c[j] < -1e-25:\n",
    "            structure[i].frac_coords[j] = 0\n",
    "        if c[j] == 1:\n",
    "            structure[i].frac_coords[j] = 0\n",
    "        if c[j] < -1e-5 and c[j] > -1e-1:\n",
    "            structure[i].frac_coords[j] = c[j]+1\n",
    "        if c[j] < 1.1 and c[j] > 1:\n",
    "            structure[i].frac_coords[j] = c[j]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f7a5672-60b8-478b-a703-b44dfe9f1242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbf30da8-890a-4dbf-b924-e878ecd80553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unit cell as matrix zero values??? yes\n",
    "cell = [list(i) for i in structure.lattice.matrix]\n",
    "#summary of crystal characteristics\n",
    "summary = str(structure).split(\"\\n\")[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b22aba9-da0f-4562-8557-c998819d8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_formula=summary[0].split(\"(\")[1].split(\")\")[0].replace(\" \",\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b544ea95-4d3f-4846-bbf5-191e16c64be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp != None:\n",
    "    #modifile(\"cif.xyz\", \"w\", temp)\n",
    "    xyz = XYZ.from_file(temp).as_dataframe()\n",
    "    species = xyz['atom'].tolist()\n",
    "    x = xyz['x'].tolist()\n",
    "    y = xyz['y'].tolist()\n",
    "    z = xyz['z'].tolist()\n",
    "    xyzs = [[x[i], y[i], z[i]] for i in range(len(x))]\n",
    "    xyzs_template = [[species[i], x[i], y[i], z[i]] for i in range(len(x))]\n",
    "    substructure = Structure(structure.lattice, species, xyzs, coords_are_cartesian=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e6e92c7-0057-4ea6-abf5-557689e8136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time so far\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04c44b74-edd2-46c8-bf98-d791b4f38fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a bunch of shifts to the coordinates\n",
    "hkls = []\n",
    "for h in range(-1,2):\n",
    "    for k in range(-1,2):\n",
    "        for l in range(-1,2):\n",
    "            hkls.append([h,k,l])\n",
    "coord_shifts = []\n",
    "cell_array = np.array(cell)\n",
    "for k in range(len(hkls)):\n",
    "    coord_shifts.append(np.dot(hkls[k], cell_array))\n",
    "coord_shifts = np.array(coord_shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83eb0839-197e-46cb-8a7e-6051dffac861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the supercell with all the extra stuff\n",
    "sup = structure.copy()\n",
    "sup.make_supercell(2)\n",
    "#neighbors in the periodic supercell\n",
    "nn = structure.get_all_neighbors(radius)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d5684ba-4009-4c90-a740-6534380428a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get voronoi data for all relevant atoms\n",
    "if temp != None:\n",
    "    allvnn = []\n",
    "    getvoro = [i for i in xyzs]\n",
    "    for i in range(len(substructure)):\n",
    "        for j in range(len(structure)):\n",
    "            test_struct = np.transpose(np.repeat(structure[j].coords, 27).reshape(3, 27))\n",
    "            test_sub = np.transpose(np.repeat(substructure[i].coords, 27).reshape(3, 27))\n",
    "            sub = test_struct - test_sub + coord_shifts\n",
    "            w = np.where(np.bincount(np.where(np.logical_and(sub < 0.001, sub > -0.001))[0])==3)[0]\n",
    "            if len(w) == 1:\n",
    "                for k in range(len(nn[j])):\n",
    "                    getvoro.append(nn[j][k].coords)\n",
    "                break\n",
    "    getvoro = np.unique(np.array(getvoro).round(decimals=6), axis=0)\n",
    "    getvoro_frac = np.dot(getvoro, np.linalg.inv(np.array(cell)))\n",
    "    getvoro_where = np.where(np.logical_and(getvoro_frac>-0.001, getvoro_frac<1), 1, 0)\n",
    "    getvoro_in_uc = np.where(np.sum(getvoro_where, axis=1)==3)[0]\n",
    "    getvoro = np.unique(getvoro[getvoro_in_uc], axis=0)\n",
    "    for i in range(len(structure)):\n",
    "        for j in range(len(getvoro)):\n",
    "            if np.all(np.isclose(getvoro[j], structure[i].coords)):\n",
    "                allvnn.append([value for key, value in VoronoiNN().get_voronoi_polyhedra(structure,i).items()])\n",
    "                break\n",
    "        else:\n",
    "            allvnn.append([])\n",
    "else:\n",
    "    allvnn = VoronoiNN().get_all_nn_info(structure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1a5242f-75c3-4604-949c-0d3852632513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows voronoi polynomial for each one\n",
    "#allvnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17b71a5b-12e8-40d2-a34c-2579072f7815",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_options = []\n",
    "neighbor_weights = []\n",
    "neighbors = []\n",
    "neighbors2 = []\n",
    "cns = []\n",
    "stoich = []\n",
    "elems = []\n",
    "data = []\n",
    "used_for = []\n",
    "vectors = []\n",
    "geo = []\n",
    "geo2 = []\n",
    "struct_coords = []\n",
    "template = []\n",
    "template2 = []\n",
    "template3 = []\n",
    "vols = []\n",
    "s_tot = []\n",
    "en = []\n",
    "rad = []\n",
    "en2 = []\n",
    "rad2 = []\n",
    "v = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1716aad0-ad58-424c-b6bc-040b034ff23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(allvnn)):\n",
    "    if structure[i].specie.Z in stoich:\n",
    "        #adding onto the cumulative total of that element\n",
    "        s_tot[stoich.index(structure[i].specie.Z)] += 1\n",
    "        #cube of electronegativity???\n",
    "        en.append(PT.Element(elems[-1]).X**3)\n",
    "        #cube of radius\n",
    "        rad.append(PT.Element(elems[-1]).atomic_radius_calculated**3)\n",
    "    else:\n",
    "        #which atomic number\n",
    "        stoich.append(structure[i].specie.Z)\n",
    "        #element total\n",
    "        s_tot.append(1)\n",
    "        #symbol of element\n",
    "        elems.append(structure[i].specie.symbol)\n",
    "        #electroneg cubed??? jonathan\n",
    "        en.append(PT.Element(elems[-1]).X**3)\n",
    "        #radius cubed\n",
    "        rad.append(PT.Element(elems[-1]).atomic_radius_calculated**3)\n",
    "ensum = sum(en)/len(en) #avg cubed en\n",
    "radsum = sum(rad)/len(rad) #avg cubed rad \n",
    "for i in range(len(en)):\n",
    "    en2.append(en[i]/ensum) #cubed en normalized to average\n",
    "    rad2.append(rad[i]/radsum) #cubed rad normalized to average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4d641c-bf27-46bf-8e1c-8c52a4f7bbdb",
   "metadata": {},
   "source": [
    "**La did not work--https://pymatgen.org/pymatgen.core.html#pymatgen.core.periodic_table.Element.atomic_radius_calculated\n",
    "weird thing with wiki reference, using calculated column; La, Ce, H have values but no reference\n",
    "\n",
    "look into psuedo manually adding them?\n",
    "\n",
    "ordered sites only--no partial occupancy? do we do the max prob? choose one probabalistically etc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ec923ea-08c8-4e59-9391-66506f1df6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(allvnn)): #each atom\n",
    "    neighbors.append([]) #new list for each one\n",
    "    neighbors2.append([])\n",
    "    vols.append([])\n",
    "    cns.append([0,0])\n",
    "    for j in range(len(allvnn[i])): #each neighbor\n",
    "        neighbors2[i].append(allvnn[i][j]['site'].to_unit_cell()) #translated to unit cell\n",
    "        neighbors[i].append(allvnn[i][j]['site']) #general space?\n",
    "        if temp != None:\n",
    "            vols[i].append(round(allvnn[i][j]['volume'], 6)) #assigned vol to each\n",
    "        else:\n",
    "            vols[i].append(round(allvnn[i][j]['poly_info']['volume'], 6)) #assigned vol to each\n",
    "        if allvnn[i][j]['site'].specie.Z == structure[i].specie.Z: #is it a like interaction? !!!\n",
    "            cns[i][0] += 1 #yes\n",
    "        else:\n",
    "            cns[i][1] += 1 #no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a444e7a3-9b66-455e-ae76-46b810c9b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = time.time()\n",
    "\n",
    "sn = sup.get_all_neighbors(radius) #neigbors of each 8n in the supercell\n",
    "\n",
    "dx = 2 # search x angstroms beyond the unit cell.\n",
    "def within_range(d, dx, a, b, c):\n",
    "    if -dx <= d[0] and d[0] <= a+dx:\n",
    "        if -dx <= d[1] and d[1] <= b+dx:\n",
    "            if -dx <= d[2] and d[2] <= c+dx:\n",
    "                return(True)\n",
    "            else:\n",
    "                return(False)\n",
    "        else:\n",
    "            return(False)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59bc8c65-cab8-49d2-bcfc-26c41a366266",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sup)):\n",
    "    a = structure.lattice.a\n",
    "    b = structure.lattice.b\n",
    "    c = structure.lattice.c\n",
    "    d = sup[i].coords\n",
    "    for j in range(len(sn[i])):\n",
    "        d = sn[i][j].coords\n",
    "        if within_range(d, dx, a, b, c):\n",
    "            template.append([sn[i][j].specie.symbol, d[0], d[1], d[2]]) #adding on the ones that are in the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8491cbe7-c532-4145-a01a-1f934e69158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[template2.append(x) for x in template if x not in template2]\n",
    "template3 = template2.copy() #taking unique ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c5b8054-c2d9-4f59-8440-bb76c99580f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(structure)):\n",
    "    s = structure[i] #each element in the structure added to list of counts\n",
    "    if s.specie.Z in stoich:\n",
    "        s_tot[stoich.index(s.specie.Z)] += 1\n",
    "    else:\n",
    "        stoich.append(s.specie.Z)\n",
    "        s_tot.append(1)\n",
    "        elems.append(s.specie.symbol)\n",
    "    geo.append([s.specie.symbol, round(s.coords[0],4), round(s.coords[1],4), round(s.coords[2],4)]) #element and coords\n",
    "    geo2.append([round(s.frac_coords[0],4), round(s.frac_coords[1],4), round(s.frac_coords[2],4)]) #coords\n",
    "    struct_coords.append(s.coords)\n",
    "struct_coords = np.array(struct_coords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caaaec68-abd7-4734-9e4f-6a19a95052a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_voxel = np.array([np.array(i, dtype=np.float16) for i in cell])\n",
    "positions = []\n",
    "x = []\n",
    "y = []\n",
    "z = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86d29a0d-355c-470e-963f-d7bd9db8ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(geo2)):\n",
    "    positions.append(np.dot(geo2[i], cell_voxel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b6b80fe-4e86-4f71-9b5f-55ca580a0c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp != None:\n",
    "    coords = np.array([i.frac_coords for i in substructure]) \n",
    "    mincv = np.min(coords, axis=0)\n",
    "    maxcv = np.max(coords, axis=0)\n",
    "    for i in range(3):\n",
    "        if mincv[i] < 0:\n",
    "            mincv[i] = 0\n",
    "        if maxcv[i] > 1:\n",
    "            maxcv[i] = 1\n",
    "    coords_first_uc = []\n",
    "    for i in range(len(xyzs)):\n",
    "        c = coords[i]\n",
    "        for j in range(3):\n",
    "            if c[j] < 0:\n",
    "                c[j] = c[j] + 1\n",
    "            if c[j] >= 1:\n",
    "                c[j] = c[j] - 1\n",
    "            if c[j] < 1e-5:\n",
    "                c[j] = 0\n",
    "        coords_first_uc.append([round(c[0],4), round(c[1],4), round(c[2],4)])\n",
    "    ucfuc = []\n",
    "    [ucfuc.append(p) for p in coords_first_uc if p not in ucfuc]\n",
    "    ucfuc = np.array(ucfuc)\n",
    "    xyzs_first_uc = np.dot(ucfuc, cell_voxel)\n",
    "    xyzs_first_uc = np.array([[round(i[0],4), round(i[1],4), round(i[2],4)] for i in xyzs_first_uc])\n",
    "    for i in range(len(xyzs_first_uc)):\n",
    "        x.append(xyzs_first_uc[i][0])\n",
    "        y.append(xyzs_first_uc[i][1])\n",
    "        z.append(xyzs_first_uc[i][2])\n",
    "    vca_small = []\n",
    "    vca_weights_small = []\n",
    "    cubic_grid_small = []\n",
    "    filter_indicies = []\n",
    "    geo_list = [list(l) for l in geo2]\n",
    "    ucfuc_list = [list(l) for l in ucfuc]\n",
    "    for i in range(len(ucfuc_list)):\n",
    "        if ucfuc_list[i] in geo_list:\n",
    "            filter_indicies.append(geo_list.index(ucfuc_list[i]))\n",
    "else:\n",
    "    for i in range(len(positions)): #separating out each dimension\n",
    "        x.append(positions[i][0])\n",
    "        y.append(positions[i][1])\n",
    "        z.append(positions[i][2])\n",
    "    filter_indicies = [i for i in range(len(structure))] #number of sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fac13a9f-8083-4c43-8042-5714eac48d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = []\n",
    "#!!!\n",
    "el_data={}\n",
    "for i in range(len(s_tot)):\n",
    "    el_data[i]=df2[stoich[i]]\n",
    "#el1_data = df2[stoich[0]]\n",
    "#el2_data = df2[stoich[1]] #why only the first two??? only used for binarys??? !!!\n",
    "    \n",
    "e_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a460892-b46e-4050-80d4-03704349e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!\n",
    "for l in range(14):\n",
    "    value=0\n",
    "    for i in range(len(s_tot)):\n",
    "        value+=el_data[i][l]*s_tot[i]\n",
    "    e_data.append(value/sum(s_tot)) # weighted average of each element's data, whole crystal\n",
    "    value2=0\n",
    "    for i in range(len(s_tot)):\n",
    "        value2+=(el_data[i][l]-e_data[-1])**2*s_tot[i]\n",
    "    e_data.append(np.sqrt(value2/sum(s_tot)))\n",
    "    #e_data.append((el1_data[l]*s_tot[0] + el2_data[l]*s_tot[1])/(s_tot[0]+s_tot[1])) # weighted average of each element's data, whole crystal\n",
    "    #e_data.append(np.sqrt((s_tot[0]*(el1_data[l]-e_data[-1])**2 + (s_tot[1]*(el2_data[l]-e_data[-1])**2))/(s_tot[0]+s_tot[1]))) # weighted square deveation of each element's data\n",
    "\n",
    "\n",
    "\n",
    "#e_data.append((el1_data[l]*s_tot[0] + el2_data[l]*s_tot[1])/(s_tot[0]+s_tot[1])) # weighted average of each element's data, whole crystal\n",
    "#e_data.append(np.sqrt((s_tot[0]*(el1_data[l]-e_data[-1])**2 + (s_tot[1]*(el2_data[l]-e_data[-1])**2))/(s_tot[0]+s_tot[1]))) # weighted square average of each element's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "443c643e-28d3-4a1d-aa87-ff38d1835437",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(structure)):\n",
    "    if i in filter_indicies:\n",
    "        for j in range(len(neighbors[i])): #for each neighbor atom of each one\n",
    "            ct1_data = df2[structure[i].specie.Z] #the element in the structure info\n",
    "            ct2_data = df2[neighbors[i][j].specie.Z] # the other one info\n",
    "            length = round(np.linalg.norm(structure[i].coords - neighbors[i][j].coords), 4) #gets magnitude of length diff\n",
    "            test = np.transpose(np.repeat(neighbors2[i][j].coords, len(structure)).reshape(3, len(structure))) #repeat unit cell translated coords n times\n",
    "            sub = test - struct_coords #difference of everything to the contact one\n",
    "            k = np.where(np.bincount(np.where(np.isclose(sub,np.zeros(sub.shape),rtol=0.001,atol=0.000001))[0])==3)[0][0] #the one the contact is\n",
    "            cns_neighbor = cns[k] #interaction characters (like/unlike)\n",
    "            sc = structure[i].frac_coords.tolist() #location of the first\n",
    "            nc = neighbors[i][j].frac_coords.tolist() #location of the neighbor\n",
    "            if [i, k, sc, nc] in unique or [k, i, nc, sc] in unique: #so as to not repeat a contact twice from each's perspective\n",
    "                continue\n",
    "            else:\n",
    "                vven = round(vols[i][j]*(en2[i]+en2[k]), 4) #vol of contact times sum of cubed averaged electronegativity\n",
    "                neighbor_weights.append(vven*0.1*(1/length)) #weighting neighbor by the vol-EN and closer ones more\n",
    "                is_same = 0 if (neighbors2[i][j].coords == neighbors[i][j].coords).all() else 1 #same unit cell?\n",
    "                #adding in element properties of interest\n",
    "                sum_met_rad = (ct1_data[2] + ct2_data[2])/100\n",
    "                sum_met_vol = round((ct1_data[2]/100)**3 + (ct2_data[2]/100)**3, 4)\n",
    "                length_cubed = round(length**3, 4)\n",
    "                en_range = round(abs(ct1_data[6] - ct2_data[6]), 4)\n",
    "                #comparisons between 'expected' and the structural ones\n",
    "                diff_len = round(sum_met_rad - length, 4)\n",
    "                diff_vorovol = round(vven - length_cubed, 4)\n",
    "                diff_metvol = round(sum_met_vol - length_cubed, 4)\n",
    "                extras = [length, vven, sum_met_rad, sum_met_vol, length_cubed, en_range, diff_len, diff_vorovol, diff_metvol] #storing these\n",
    "                c_data = []\n",
    "                cns_data = []\n",
    "                for l in range(14): #for all 14 base properties\n",
    "                    c_data.append((ct1_data[l]+ct2_data[l])/2) #average\n",
    "                    c_data.append(abs(ct1_data[l]-ct2_data[l])/2) #half diff\n",
    "                for l in range(2):\n",
    "                    cns_data.append((cns[i][l]+cns_neighbor[l])/2) #avg of the like/unlike of both\n",
    "                    cns_data.append(abs(cns[i][l]-cns_neighbor[l])/2) #same thing? should be neg??? (changed)\n",
    "                data.append(extras + e_data + c_data + cns_data) #setting up feature list\n",
    "                vectors.append(neighbors[i][j].coords - structure[i].coords) # adding on the spatial distance\n",
    "                if is_same == 0:\n",
    "                    used_for.append([i,k]) #if in the unit cell, this is the represenative one??\n",
    "                else:\n",
    "                    used_for.append([i,len(structure)]) #just saying it's something else for now??\n",
    "                unique.append([i, k, structure[i].frac_coords.tolist(), neighbors[i][j].frac_coords.tolist()]) #recording the one done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4dacdde-98c3-41be-8d2e-7ca7f86485a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "npdata = np.array([np.array(line) for line in data]) #into numpy\n",
    "npdata3 = [list(a) for a in npdata] #just data again\n",
    "assignments = []\n",
    "unique_npdata = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aae1a929-729b-4ec5-a8e5-3d7f14807805",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(npdata3)):\n",
    "    if npdata3[i] not in unique_npdata:\n",
    "        #if npdata3[i][:28]+npdata3[i][42:56]+npdata3[i][28:42]+npdata3[i][56:] not in unique_npdata:\n",
    "        if npdata3[i][:37]+npdata3[i][51:65]+npdata3[i][37:51]+npdata3[i][65:] not in unique_npdata: #swap to diff before of avgs. why??? ranges wrong??? changed\n",
    "            unique_npdata.append(npdata3[i]) #unique data one\n",
    "            assignments.append(len(unique_npdata)-1)\n",
    "        else:\n",
    "            assignments.append(unique_npdata.index(npdata3[i][:37]+npdata3[i][51:65]+npdata3[i][37:51]+npdata3[i][65:])) #which one it's using\n",
    "            #assignments.append(unique_npdata.index(npdata3[i][:28]+npdata3[i][42:56]+npdata3[i][28:42]+npdata3[i][56:])) #changed\n",
    "    else:\n",
    "        assignments.append(unique_npdata.index(npdata3[i])) #record which assignment used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f6b4c45-22c3-49d6-9725-89b219728cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_npdata = [np.array(a) for a in unique_npdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b22a89b-00a6-4e3a-8693-bb93d7032d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./rfc.pickle', 'rb') #loading classifier\n",
    "rfc = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e84ec5a4-36b4-48aa-b00d-f8a61a54a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rfc = rfc.predict(unique_npdata) #which group they are in: 0 neg, 1 int, 2 pos\n",
    "predictions_rfc = np.reshape(pred_rfc, (pred_rfc.shape[0],1)) #reshape into arrays\n",
    "npdata2 = np.hstack((unique_npdata, predictions_rfc)) #adding predictions to each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6027ab62-207a-4a31-8282-f920647c96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = 0 #closing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "197c1e85-8541-4063-a688-731bba0db042",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./rfr.pickle', 'rb') #opening regressor\n",
    "rfr = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34985dce-2c2a-466f-8db2-7329cfef509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_predictions_rfr = rfr.predict(npdata2) #making the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35a39e14-cf31-4a61-8eee-63f9765a5019",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = 0 #closing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dda3d86a-a99b-457f-874a-ef0b9dbbeb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rfr = []\n",
    "for i in range(len(assignments)):\n",
    "    predictions_rfr.append(unique_predictions_rfr[assignments[i]]) #adding the predicted value for each contact\n",
    "predictions_rfr = np.array(predictions_rfr)\n",
    "geo2 = np.array([np.array(i) for i in geo2]) #each location in fractional \n",
    "neighborr = unique.copy() #each unique neighbor connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce7047c8-98aa-4775-9c08-e2a8c63d14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d325e9d4-36c5-43b2-825c-da36a0564481",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(neighborr)):\n",
    "    for i in range(3): #xyz\n",
    "        if neighborr[j][2][i] >= 0 and neighborr[j][2][i] < 1: #if main is in unit cell\n",
    "            neighborr[j][2][i] = 0 #the unit cell\n",
    "        elif neighborr[j][2][i] >= -1 and neighborr[j][2][i] < 0: #if main is in in one below\n",
    "            neighborr[j][2][i] = -1 #the one below\n",
    "        else: # neighbor should be greater than one\n",
    "            neighborr[j][2][i] = 1 #the one above\n",
    "        if neighborr[j][3][i] >= 0 and neighborr[j][3][i] < 1: #if neighbor is in unit cell\n",
    "            neighborr[j][3][i] = 0\n",
    "        elif neighborr[j][3][i] >= -1 and neighborr[j][3][i] < 0: #if neighbor is in one below\n",
    "            neighborr[j][3][i] = -1\n",
    "        else: # neighbor should be greater than one\n",
    "            neighborr[j][3][i] = 1 #if neighbor is in one above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c556802-94ec-4ffe-bb81-66bac3961b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_verts = []\n",
    "contact_atoms = []\n",
    "\n",
    "buffer = 7\n",
    "voxels_per_angstrom = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5693b267-1029-42d8-93f9-d86850e9b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cubic_grid(voxels_per_angstrom, mins=[0,0,0], maxs=[1,1,1], buff=0):\n",
    "    # determine the cell vector lengths\n",
    "    lena = np.sqrt(cell_voxel[0][0]**2 + cell_voxel[0][1]**2 + cell_voxel[0][2]**2) #a\n",
    "    lenb = np.sqrt(cell_voxel[1][0]**2 + cell_voxel[1][1]**2 + cell_voxel[1][2]**2) #b\n",
    "    lenc = np.sqrt(cell_voxel[2][0]**2 + cell_voxel[2][1]**2 + cell_voxel[2][2]**2) #c\n",
    "    # calculate the length needed for increments, which is (max-min) + 2 * buffer, or len, whichever is less.\n",
    "    lengths = [lena, lenb, lenc]\n",
    "    start = [0,0,0]\n",
    "    stop = [1,1,1]\n",
    "    for i in range(3):\n",
    "        # along a, b, and c, if the substructure is entirely contained within the unit cell, we don't need the whole range.\n",
    "        # note: if the substructure lies along the unit cell edge on one side, but not the other, we can't do this.\n",
    "        if mins[i]-(buff/lengths[i]) > 0: #the min (0) is more than the buffer as a percent of the side\n",
    "            if maxs[i]+(buff/lengths[i]) < 1: #and the max (1) plus the puffer and side length is over 1 (usually true)\n",
    "                start[i] = mins[i]-(buff/lengths[i]) #start and stop get buffered\n",
    "                stop[i] = maxs[i]+(buff/lengths[i]) \n",
    "        if lengths[i] > ((maxs[i]-mins[i]) * lengths[i] + buff * 2): #length larger than max-min times range with buffer\n",
    "            lengths[i] = ((maxs[i]-mins[i]) * lengths[i] + buff * 2) #use lower value for new lengths\n",
    "    # calculate the number of increments along each vector\n",
    "    na = int(math.ceil(lengths[0] * voxels_per_angstrom)) + 1\n",
    "    nb = int(math.ceil(lengths[1] * voxels_per_angstrom)) + 1\n",
    "    nc = int(math.ceil(lengths[2] * voxels_per_angstrom)) + 1\n",
    "    na_max = int(math.ceil(lena * voxels_per_angstrom)) #position of the unit cell in the increment units\n",
    "    nb_max = int(math.ceil(lenb * voxels_per_angstrom))\n",
    "    nc_max = int(math.ceil(lenc * voxels_per_angstrom))\n",
    "    # create the fractional coordinates along each vector\n",
    "    a_space = np.linspace(start[0], stop[0], na, dtype=\"float16\")\n",
    "    b_space = np.linspace(start[1], stop[1], nb, dtype=\"float16\")\n",
    "    c_space = np.linspace(start[2], stop[2], nc, dtype=\"float16\")\n",
    "    # center the coordinates (ex.: [0.0, 0.1, ... 0.8, 0.9] ==> [0.05, 0.015, ... 0.85, 0.95]\n",
    "    a_space = (a_space[:-1] + a_space[1:]) / 2  # gets centers of the voxels\n",
    "    b_space = (b_space[:-1] + b_space[1:]) / 2  # gets centers of the voxels\n",
    "    c_space = (c_space[:-1] + c_space[1:]) / 2  # gets centers of the voxels\n",
    "    # combine a, b, and c coordinates\n",
    "    grid_positions = np.array([np.array([x, y, z], dtype=\"float16\") for x in a_space for y in b_space for z in c_space])\n",
    "    return(np.dot(grid_positions, cell_voxel), [na_max, nb_max, nc_max]) #matrix product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90babbaf-bec1-49e7-9899-b9f64f1a7032",
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp != None:\n",
    "    cubic_grid,voxel_max = make_cubic_grid(voxels_per_angstrom, mincv, maxcv, buffer) #more complex\n",
    "else:\n",
    "    cubic_grid,voxel_max = make_cubic_grid(voxels_per_angstrom) #only a function of vpa\n",
    "vmt = voxel_max[0]*voxel_max[1]*voxel_max[2] #area of the unit cell in those units as a prism\n",
    "#vca = [] # added as [index of p1, index of p2, [h,k,l] of p1, [h,k,l] of p2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f812ab9a-276d-4f86-bf89-83892805e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = []\n",
    "p_test_hkl = []\n",
    "p_test_xyz = []\n",
    "p_test_hkl2 = []\n",
    "p_test_xyz2 = []\n",
    "p_test_hkl3 = []\n",
    "p_test_xyz3 = []\n",
    "for i in range(len(positions)):\n",
    "    for h in range(-2,3):\n",
    "        for k in range(-2,3):\n",
    "            for l in range(-2,3):\n",
    "                p_test = []\n",
    "                for j in range(3):\n",
    "                    p_test.append(positions[i][j] + cell_voxel[0][j]*h + cell_voxel[1][j]*k + cell_voxel[2][j]*l) #getting the vlaues for each one when transferred to the next unit cell\n",
    "                p_test_hkl2.append([i,h,k,l])\n",
    "                p_test_xyz2.append(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c268ec58-1825-402c-bf9c-a823d8cc187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = time.time()\n",
    "\n",
    "minmax = [[min(x)-buffer, max(x)+buffer],[min(y)-buffer, max(y)+buffer],[min(z)-buffer, max(z)+buffer]] #buffer the positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f4ef4cb-4b70-41fa-b7dd-23b90492f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(p_test_hkl2)): #for each shift of each atom\n",
    "    pp = p_test_xyz2[i] #the location of it\n",
    "    if pp[0] > minmax[0][0] and pp[0] < minmax[0][1]: #in x range\n",
    "        if pp[1] > minmax[1][0] and pp[1] < minmax[1][1]: #in y range\n",
    "            if pp[2] > minmax[2][0] and pp[2] < minmax[2][1]: #in z range\n",
    "                p_test_hkl3.append(p_test_hkl2[i]) #adding on the inlimit ones\n",
    "                p_test_xyz3.append(np.array(p_test_xyz2[i], dtype=np.float32)) #samedeal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d73b990e-6731-489d-a22d-63e4139ce4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp != None:\n",
    "    # remove atoms from superstructure which are more than <buffer> angstroms away from any one atom in the substructure\n",
    "    distances = cdist(p_test_xyz3, xyzs_first_uc)\n",
    "    mins = np.min(distances, axis=1)\n",
    "    maybe = np.where(mins<buffer,1,0)\n",
    "    for i in range(len(p_test_hkl3)):\n",
    "        if maybe[i] == 1:\n",
    "            p_test_hkl.append(p_test_hkl3[i])\n",
    "            p_test_xyz.append(p_test_xyz3[i])\n",
    "else:\n",
    "    p_test_xyz = p_test_xyz3\n",
    "    p_test_hkl = p_test_hkl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d699f5f8-eb1b-45f1-a186-27b1e0dbaa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test_xyz = np.array(p_test_xyz, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "672fa2e6-5c94-498b-805a-9e3aaa1f36fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp != None:\n",
    "    cell_voxel = np.array(cell_voxel, dtype=\"float32\")\n",
    "    newmin = np.dot(np.min(p_test_xyz, axis=0), np.linalg.inv(cell_voxel))\n",
    "    newmax = np.dot(np.max(p_test_xyz, axis=0), np.linalg.inv(cell_voxel))\n",
    "    for i in range(3):\n",
    "        if newmin[i] < 0:\n",
    "            newmin[i] = 0\n",
    "        if newmax[i] > 1:\n",
    "            newmax[i] = 1\n",
    "    newmin = np.dot(newmin, cell_voxel)\n",
    "    newmax = np.dot(newmax, cell_voxel)\n",
    "    august = np.where(np.logical_and(cubic_grid > newmin, cubic_grid < newmax))[0]\n",
    "    sept = np.bincount(august)\n",
    "    octo = np.where(sept==3)[0]\n",
    "    new_grid = cubic_grid[octo]\n",
    "    cubic_grid = new_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b3678bc-5ec9-403e-8f2f-a6daa6de3d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = int(len(cubic_grid)/4) #getting quartiles of the sample points\n",
    "q2 = int(len(cubic_grid)/2)\n",
    "q3 = int(3*len(cubic_grid)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e43ef884-ed9d-49f2-8a59-6b6643b9f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ1 = cdist(cubic_grid[:q1],p_test_xyz) #distance of each grid point to the atoms\n",
    "summ2 = cdist(cubic_grid[q1:q2],p_test_xyz) #second quartile\n",
    "summ3 = cdist(cubic_grid[q2:q3],p_test_xyz) #3rd\n",
    "summ4 = cdist(cubic_grid[q3:],p_test_xyz) \n",
    "summ5 = np.concatenate((summ1,summ2), axis=0, dtype=\"float16\") #combined first half\n",
    "summ1, summ2 = [], []  #clear\n",
    "summ6 = np.concatenate((summ3,summ4), axis=0, dtype=\"float16\") #second half\n",
    "summ3, summ4 = [], [] #clear\n",
    "summ = np.concatenate((summ5,summ6),axis=0) #full version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1be741e1-1f14-47db-841f-6a373fa60c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = np.min(summ, axis=1) #lowest distance value in each set (reflects closest voxel!)\n",
    "ss = np.partition(summ, 1)[:,1] + 1/voxels_per_angstrom #all the second closest distances, plus a voxel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ee8683a-48de-425d-a7a8-a9e597b60c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "vca = []\n",
    "vca_weights = []\n",
    "cubic_grid_big = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae3731eb-0c5f-437c-9a20-0968d1c3a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "apv = 0.5/voxels_per_angstrom #half of a voxel length\n",
    "summlen = len(summ[0]) #total atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2566ef7-7323-435c-bdac-5efcf7de79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(summ)): #for each grid point\n",
    "    bi = np.where(summ[i] <= ss[i])[0] #(two) lowest values\n",
    "    b = summ[i][bi] #those lowest distances\n",
    "    c = [a+b for a,b in combinations(b,2)] #sum of pairs of distances among them\n",
    "    ci = [[a,b] for a,b in combinations(bi,2)] #pairs of indices\n",
    "    d = min(c) + apv #min sum distance plus half a cell length\n",
    "    e = [ci[j] for j in range(len(c)) if c[j] <= d]# within 0.5 voxlen of the lowest summed distance ones\n",
    "    for j in range(len(e)): #for each of the ties\n",
    "        p1 = p_test_hkl[e[j][0]] #which atom & hkl the lowest refers to\n",
    "        p2 = p_test_hkl[e[j][1]] #which atomh & hkl the 2nd lowest refers to\n",
    "        vca.append([p1[0]] + [p2[0]] + p1[1:] + p2[1:]) #the two closest atoms and their hkl coordinates\n",
    "        cubic_grid_big.append(cubic_grid[i]) #making the cubic grid of points\n",
    "        vca_weights.append(1/len(e)) #for how many close ones, that's the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b269caa-0dfe-4614-bd6d-d146d5e1ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = [] #clear\n",
    "\n",
    "t6 = time.time()\n",
    "\n",
    "unique_contacts = []\n",
    "unique_contacts_array = []\n",
    "voxel_groups = []\n",
    "uca, reconstruct = np.unique(np.array(vca), axis=0, return_inverse=True) #unique contacts and the label for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39106a56-48b1-40a8-b7b6-1a004f659799",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(uca)):\n",
    "    voxel_groups.append(np.where(reconstruct == i)[0]) #adding the indices for each of the unique contacts\n",
    "    unique_contacts.append([uca[i][0], uca[i][1], list(uca[i][2:5]), list(uca[i][5:])]) #adding in the unique ones as a separated list\n",
    "    unique_contacts_array.append(np.concatenate((uca[i][0], uca[i][1], uca[i][2:5], uca[i][5:]), axis=None)) #all one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6af7e7ab-a37d-49ac-83db-70099d99865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_contacts2 = unique_contacts.copy()\n",
    "voxel_groups2 = voxel_groups.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "994d1695-2258-47cb-991f-e6e8c78c7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "hklsnp = np.array(hkls) # as array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7dfd843c-2a66-42d9-81f9-d91561116972",
   "metadata": {},
   "outputs": [],
   "source": [
    "uc2 = np.array([unique_contacts[i][2] for i in range(len(unique_contacts))]) #the first atom's hkl\n",
    "uc3 = np.array([unique_contacts[i][3] for i in range(len(unique_contacts))]) #the second one's hkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b8e7e41-c9fb-44d1-9087-60e5e08d4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making each unique contact (atoms and hkl) and translating it in all directions with hkl\n",
    "uc_options = np.array([np.concatenate((unique_contacts[i][:2], uc2[i]+j, uc3[i]+j), axis=None)for i in range(len(unique_contacts)) for j in hklsnp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b2a42ba-a813-45f7-8ebf-6f8b826ea176",
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_groups = []\n",
    "paired_groups_hkl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02c185f8-eea6-44e2-a535-f44e5486d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(unique_contacts)):\n",
    "    test = np.transpose(np.repeat(unique_contacts_array[i], 27*len(unique_contacts)).reshape(8, 27*len(unique_contacts))) #making it match the many dimension one\n",
    "    sub = test - uc_options #seeing if it matches\n",
    "    w = np.where(np.bincount(np.where(sub==0)[0])==8)[0] #seeing if it matches fully\n",
    "    paired_groups.append(w//27) #which unique contact gets the match\n",
    "    paired_groups_hkl.append(hklsnp[w%27]) #which coordinate shift matches the one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3c80130d-6851-4b77-bb19-95d3dc2a9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(paired_groups)):\n",
    "    new = []\n",
    "    newhkl = []\n",
    "    for j in range(len(paired_groups[i])): #each index of the same contacts for each contact\n",
    "        if paired_groups[i][j] not in new:\n",
    "            new.append(paired_groups[i][j]) #add in the index of the unique contact that gets there\n",
    "            newhkl.append(paired_groups_hkl[i][j]) #hkl shift of it\n",
    "    paired_groups[i] = new #putting in the unique indexes\n",
    "    paired_groups_hkl[i] = newhkl #putting in the unique hkls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9fd592ca-eb66-4d51-876c-aaa1629a25ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pg = []\n",
    "unique_pg_hkl = []\n",
    "for i in range(len(paired_groups)):\n",
    "    pg = sorted(paired_groups[i]) #putting things in order\n",
    "    if pg not in unique_pg:\n",
    "        unique_pg.append(paired_groups[i]) #unique paired groups\n",
    "        unique_pg_hkl.append(paired_groups_hkl[i]) #hkls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09518929-c789-4ae4-bfa3-b41be9c72adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_contacts3 = []\n",
    "voxel_groups3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "340c8837-7eef-471b-989c-9eb5cb3d4cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(unique_pg)):\n",
    "    upgi = unique_pg[i][0] #the first one\n",
    "    voxel_groups3.append(voxel_groups[upgi]) #which voxel groups near it, for all of them\n",
    "    unique_contacts3.append(unique_contacts[upgi]) #which contacts, for all of them\n",
    "    if len(unique_pg[i]) > 1: #if theres more than one unique index\n",
    "        for j in range(1,len(unique_pg[i])):\n",
    "            upgij = unique_pg[i][j] #the index\n",
    "            hkl = unique_pg_hkl[i][j] #the hkl\n",
    "            vg = voxel_groups[upgij] #the contact indices near it\n",
    "            grid_shift = np.dot(hkl, cell) #product with the cell\n",
    "            points = []\n",
    "            weights = []\n",
    "            l = len(cubic_grid_big)\n",
    "            count = 0\n",
    "            for k in range(len(vg)): #for each contact\n",
    "                points.append(cubic_grid_big[vg[k]]) #the coordinates of each contact\n",
    "                weights.append(vca_weights[vg[k]]) #weight of each point\n",
    "                voxel_groups3[-1] = np.append(voxel_groups3[-1], l+count) #adding however many over the grid size to the end\n",
    "                count += 1\n",
    "            cubic_grid_big = np.append(cubic_grid_big, points + grid_shift, axis=0) #adding on the shifted coordinates \n",
    "            vca_weights = vca_weights + weights #appending the weights of the used ones to the previous weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "344da3a3-3014-4a2c-b0c8-13f0afa98a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "uc = np.array([[0,0,0,0,0,0,0,0]]) #eight\n",
    "for i in range(len(unique_contacts3)): #for each unique one\n",
    "    u = unique_contacts3[i] #the unique contact\n",
    "    uc = np.vstack([uc, np.concatenate((np.array(u[0:2]), np.array(u[2]), np.array(u[3])))]) #rearranging into a 8 item list\n",
    "uc = uc[1:] #taking all the ones with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15afcdec-cf4d-42c2-8ab8-a59883507b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_groups4 = voxel_groups3.copy()\n",
    "unique_contacts4 = unique_contacts3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "00a7bdae-2113-44fd-9a83-abf05ec8414c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, -1, -1],\n",
       " [-1, -1, 0],\n",
       " [-1, -1, 1],\n",
       " [-1, 0, -1],\n",
       " [-1, 0, 0],\n",
       " [-1, 0, 1],\n",
       " [-1, 1, -1],\n",
       " [-1, 1, 0],\n",
       " [-1, 1, 1],\n",
       " [0, -1, -1],\n",
       " [0, -1, 0],\n",
       " [0, -1, 1],\n",
       " [0, 0, -1],\n",
       " [0, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 1, -1],\n",
       " [0, 1, 0],\n",
       " [0, 1, 1],\n",
       " [1, -1, -1],\n",
       " [1, -1, 0],\n",
       " [1, -1, 1],\n",
       " [1, 0, -1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 1],\n",
       " [1, 1, -1],\n",
       " [1, 1, 0],\n",
       " [1, 1, 1]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hkls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4ed10998-ce15-4e1d-b7e7-01374668be39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.16,  0.  ,  0.  ],\n",
       "       [-0.  ,  9.16,  0.  ],\n",
       "       [ 0.  ,  0.  ,  9.16]], dtype=float16)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "104f7800-0a8a-456b-a084-d340481afb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(neighborr)):  #each unique neighbor contact\n",
    "    if neighborr[i] in unique_contacts3: #they match, the unique contact is the neighbor one\n",
    "        pass\n",
    "    elif [neighborr[i][1], neighborr[i][0], neighborr[i][3], neighborr[i][2]] in unique_contacts3: #atom order swapped\n",
    "        pass\n",
    "    else: # quite often, a symmetrically equivalent bond has been found. For instance, missing the [0,4,[0,0,0],[0,0,-1]], but we have the [0,4,[0,0,1],[0,0,0]]\n",
    "        x = neighborr[i]\n",
    "        y = np.array(neighborr[i][2]) #first hkl\n",
    "        z = np.array(neighborr[i][3]) #second\n",
    "        for hkl in hkls:\n",
    "            s1 = np.concatenate((np.array([x[0], x[1]]), y+hkl, z+hkl)) #the contacts with hkls shifted\n",
    "            w = np.bincount(np.where(uc==s1)[0]) #find the matching ones\n",
    "            try:\n",
    "                a = max(w)\n",
    "                if max(w) == 8: #all match\n",
    "                    m = np.argmax(w)\n",
    "                    vg = voxel_groups3[m] #find the appropriate voxel of the match\n",
    "                    unique_contacts4.append(x) #add neighbor as unique contact\n",
    "                    voxel_groups4.append([])\n",
    "                    grid_shift = -np.dot(hkl, cell_voxel) #negative times ??? jonathan\n",
    "                    points = []\n",
    "                    weights = []\n",
    "                    l = len(cubic_grid_big)\n",
    "                    count = 0\n",
    "                    for j in range(len(vg)):\n",
    "                        points.append(cubic_grid_big[vg[j]]) #the coordinates of each contact\n",
    "                        weights.append(vca_weights[vg[j]]) #weight of each point\n",
    "                        voxel_groups4[-1].append(l+count) #adding however many over the grid size to the end\n",
    "                        count += 1\n",
    "                    cubic_grid_big = np.append(cubic_grid_big, points + grid_shift, axis=0) #adding on the shifted coordinates \n",
    "                    vca_weights = vca_weights + weights #appending the weights of the used ones to the previous weights\n",
    "                    break\n",
    "            except:\n",
    "                pass\n",
    "            s2 = np.concatenate((np.array([x[1], x[0]]), z+hkl, y+hkl)) #if that doesnt work, swap the hkls\n",
    "            w = np.bincount(np.where(uc==s2)[0]) #see if they match\n",
    "            try:\n",
    "                if max(w) == 8: #and do the same stuff\n",
    "                    m = np.argmax(w)\n",
    "                    vg = voxel_groups3[m]\n",
    "                    unique_contacts4.append(x)\n",
    "                    voxel_groups4.append([])\n",
    "                    grid_shift = -np.dot(hkl, cell_voxel)\n",
    "                    points = []\n",
    "                    weights = []\n",
    "                    l = len(cubic_grid_big)\n",
    "                    count = 0\n",
    "                    for j in range(len(vg)):\n",
    "                        points.append(cubic_grid_big[vg[j]])\n",
    "                        weights.append(vca_weights[vg[j]])\n",
    "                        voxel_groups4[-1].append(l+count)\n",
    "                        count += 1\n",
    "                    cubic_grid_big = np.append(cubic_grid_big, points + grid_shift, axis=0)\n",
    "                    vca_weights = vca_weights + weights\n",
    "                    break\n",
    "            except:\n",
    "                pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a678fd6a-7d47-4eb6-a1d2-fead49995764",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_groups5 = []\n",
    "unique_contacts5 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00b8de22-3f5b-4d85-a385-fb5758fd430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(unique_contacts4)): #ALL THE CONTACTS we had and we found\n",
    "    if unique_contacts4[i] in neighborr: #adding on the ones that match, contacts and voxels\n",
    "        unique_contacts5.append(unique_contacts4[i])\n",
    "        voxel_groups5.append(voxel_groups4[i])\n",
    "    elif [unique_contacts4[i][1], unique_contacts4[i][0], unique_contacts4[i][3], unique_contacts4[i][2]] in neighborr: #adding on the ones if swapped\n",
    "        unique_contacts5.append(unique_contacts4[i])\n",
    "        voxel_groups5.append(voxel_groups4[i])\n",
    "    else:\n",
    "        pass\n",
    "#now we have all and only the ones that match neighborr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "79037ca6-1c0b-450e-9dc5-4bd11c1095f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vca_weights = np.array(vca_weights) #weight of each grid point\n",
    "atom_voxels = []\n",
    "#groups = []\n",
    "#group_weights = []\n",
    "#group_scales = []\n",
    "coeffs = []\n",
    "bptable = []\n",
    "cubic_grid_big = np.array(cubic_grid_big)\n",
    "parts = []\n",
    "bptableguide=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "387f43cd-1fb6-45ef-999d-28e500f87524",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(structure)): #for each atom in the structure\n",
    "    atom_voxels.append(0)\n",
    "    coeffs.append([0 for j in range(49)]) #48 spots for coeffs per atom, why the extra 24???\n",
    "    if i in filter_indicies: # for each atom\n",
    "        for j in range(len(predictions_rfr)): #each contact\n",
    "            if i in used_for[j]: #if the atom we are looking at in is the contact\n",
    "                neigh = neighborr[j] #the relation there\n",
    "                try:\n",
    "                    index = unique_contacts5.index(neigh) #find the index of the contact\n",
    "                except:\n",
    "                    try:\n",
    "                        index = unique_contacts5.index([neigh[1], neigh[0], neigh[3], neigh[2]]) #index of the contact if swapped\n",
    "                    except:\n",
    "                        break\n",
    "                vg = voxel_groups5[index] #the voxel groups there\n",
    "                points = np.take(cubic_grid_big, vg, axis=0) - structure[i].coords #getting the nearby points as how far they are from the atom\n",
    "                weights = np.take(vca_weights, vg) #getting the number of voxels for each\n",
    "\n",
    "                if i == neigh[0]: #regularizing the order\n",
    "                    s0 = structure[neigh[0]]\n",
    "                    s1 = structure[neigh[1]]\n",
    "                else:\n",
    "                    s0 = structure[neigh[1]]\n",
    "                    s1 = structure[neigh[0]]\n",
    "                # While it seems unintuitive to multiply the weighted pressure prediction by sum(weights)/len(weights),\n",
    "                # this is entirely necessary for the bptable values to be correct.\n",
    "                prediction = sum(weights)*neighbor_weights[j]*predictions_rfr[j]/len(vg) #weighted average of pressure prediction\n",
    "                bptable.append([s0.specie.symbol, s0.coords, s1.specie.symbol, s1.coords, prediction, sum(weights), 0.5*sum(weights)*structure.volume/vmt])\n",
    "                bptableguide.append([i,j,prediction])\n",
    "                #values here: first atom/coords, second, ml-cp, number of points nearby, half (bc of two contacts for 1-sum??) of the volume of the contact taken up\n",
    "                \n",
    "                \"\"\"\n",
    "                # This code is used for diagnostics. Don't delete it, but\n",
    "                # don't run it unless necessary either, it slows the main\n",
    "                # for loop down by about a factor of 3.\n",
    "                l1 = list(neighborr[j][:2])\n",
    "                l2 = list(np.flip(neighborr[j][:2]))\n",
    "                if l1 in groups:\n",
    "                    group_weights[groups.index(l1)].append(np.sum(weights)) #add on the points of this one to its associate\n",
    "                    group_scales[groups.index(l1)].append(predictions_rfr[j]) #same deal with predictions\n",
    "                elif l2 in groups:\n",
    "                    group_weights[groups.index(l2)].append(np.sum(weights))\n",
    "                    group_scales[groups.index(l2)].append(predictions_rfr[j])\n",
    "                else:\n",
    "                    groups.append(l1) #each contact\n",
    "                    group_weights.append([np.sum(weights)]) #adding on the points that match here\n",
    "                    group_scales.append([predictions_rfr[j]]) #adding on the prediction\n",
    "                \"\"\"\n",
    "\n",
    "                atom_voxels[-1] += sum(weights) #add on the number of voxels there to the one for the atom\n",
    "\n",
    "                scale = weights*neighbor_weights[j]*predictions_rfr[j]/len(vg) #getting a micro prediction for each voxel, basically, adds up to prediction\n",
    "                h = np.hypot(np.hypot(points[:,0], points[:,1]), points[:,2]) #distance of each point to atom\n",
    "                phi = np.arctan2(points[:,1], points[:,0]) #angle in xy, azimuthal\n",
    "                theta = np.arccos(points[:,2]/h) #angle off of the z, polar angle\n",
    "                cost = np.cos(theta) #trig functions\n",
    "                sint = np.sin(theta)\n",
    "                cosp = np.cos(phi)\n",
    "                sinp = np.sin(phi)\n",
    "\n",
    "                #adding all these onto the first position for the atom\n",
    "                #REAL spherical harmonics\n",
    "                coeffs[i][0] += np.sum(np.ones(len(points))*scale*0.5*(1/math.pi)**0.5) \n",
    "                #sum of 0,0 harmonic times each contributing prediction, with a unit array in there for some reason\n",
    "\n",
    "                coeffs[i][1] += np.sum(scale*0.5*(3/(math.pi))**0.5*cost) #sum of 1,0 harmonic times contributing predictions\n",
    "                coeffs[i][2] += np.sum(-scale*(3/(8*math.pi))**0.5*sint*cosp*(2)**0.5) \n",
    "                #sum of 1,1 harmonic times contributing predictions, negative from odd rule ??? jonathan\n",
    "                coeffs[i][3] += np.sum(-scale*(3/(8*math.pi))**0.5*sint*sinp*(2)**0.5)\n",
    "                #sum of 1,-1 harmonic times contributing predictions, why negative??\n",
    "\n",
    "                coeffs[i][4] += np.sum(scale*0.25*(5/(math.pi))**0.5*(3*cost**2-1)) #sum of 2,0 harmonic times contributing predictions\n",
    "                coeffs[i][5] += np.sum(-scale*0.5*(15/(math.pi))**0.5*sint*cosp*cost) #2,1 why neg??\n",
    "                coeffs[i][6] += np.sum(-scale*0.5*(15/(math.pi))**0.5*sint*sinp*cost) #2,-1 why neg??\n",
    "                coeffs[i][7] += np.sum(scale*0.25*(15/(math.pi))**0.5*sint**2*np.cos(2*phi)) #2,2\n",
    "                coeffs[i][8] += np.sum(scale*0.25*(15/(math.pi))**0.5*sint**2*np.sin(2*phi)) #2,-2\n",
    "\n",
    "                coeffs[i][9] += np.sum(scale*0.25*(7/(math.pi))**0.5*(5*cost**3-3*cost)) #3,0\n",
    "                coeffs[i][10] += np.sum(-scale*0.125*(21/(math.pi))**0.5*sint*(5*cost**2-1.0)*cosp*(2)**0.5) #3,1 i suppose\n",
    "                coeffs[i][11] += np.sum(-scale*0.125*(21/(math.pi))**0.5*sint*(5*cost**2-1.0)*sinp*(2)**0.5) #and so on. trust.\n",
    "                coeffs[i][12] += np.sum(scale*0.25*(105/(2*math.pi))**0.5*sint**2*(cost)*np.cos(2*phi)*(2)**0.5)\n",
    "                coeffs[i][13] += np.sum(scale*0.25*(105/(2*math.pi))**0.5*sint**2*(cost)*np.sin(2*phi)*(2)**0.5)\n",
    "                coeffs[i][14] += np.sum(-scale*0.125*(35/(math.pi))**0.5*sint**3*np.cos(3*phi)*(2)**0.5)\n",
    "                coeffs[i][15] += np.sum(-scale*0.125*(35/(math.pi))**0.5*sint**3*np.sin(3*phi)*(2)**0.5)\n",
    "\n",
    "                coeffs[i][16] += np.sum(scale*(3/16)*(1/(math.pi))**0.5*(35*cost**4-30*cost**2+3)) #4,0\n",
    "                coeffs[i][17] += np.sum(-scale*(3/8)*(5/(math.pi))**0.5*sint*(7*cost**3-3*cost)*cosp*(2)**0.5)\n",
    "                coeffs[i][18] += np.sum(-scale*(3/8)*(5/(math.pi))**0.5*sint*(7*cost**3-3*cost)*sinp*(2)**0.5)\n",
    "                coeffs[i][19] += np.sum(scale*(3/8)*(5/(2*math.pi))**0.5*sint**2*(7*cost**2-1)*np.cos(2*phi)*(2)**0.5)\n",
    "                coeffs[i][20] += np.sum(scale*(3/8)*(5/(2*math.pi))**0.5*sint**2*(7*cost**2-1)*np.sin(2*phi)*(2)**0.5)\n",
    "                coeffs[i][21] += np.sum(-scale*(3/8)*(35/(math.pi))**0.5*sint**3*cost*np.cos(3*phi)*(2)**0.5)\n",
    "                coeffs[i][22] += np.sum(-scale*(3/8)*(35/(math.pi))**0.5*sint**3*cost*np.sin(3*phi)*(2)**0.5)\n",
    "                coeffs[i][23] += np.sum(scale*(3/16)*(35/(2*math.pi))**0.5*sint**4*np.cos(4*phi)*(2)**0.5)\n",
    "                coeffs[i][24] += np.sum(scale*(3/16)*(35/(2*math.pi))**0.5*sint**4*np.sin(4*phi)*(2)**0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6c81bb37-e3ab-4691-9b43-ab1e0efb6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "cpvalues=[]\n",
    "sitenames=[]\n",
    "net_pressure = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ca066953-13a0-4f10-af04-9e928370e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(atom_voxels)): #for each atom\n",
    "    net_pressure += atom_voxels[i] * 29421.0265*coeffs[i][0]*np.sqrt(4*math.pi) / 2 \n",
    "    #calculating total pressure--what is this from??? jonathan\n",
    "    data.append([structure[i].specie.symbol, '{0:.2f} GPa'.format(round(29421.0265*coeffs[i][0]*np.sqrt(4*math.pi),2))]) #reporting the pressure\n",
    "    cpvalues.append(29421.0265*coeffs[i][0]*np.sqrt(4*math.pi))\n",
    "    sitenames.append(structure[i].specie.symbol)\n",
    "# only the first value contributes. is this a problem???\n",
    "if temp == None:\n",
    "    data.append([\"Total\", '{0:.2f} GPa'.format(round(net_pressure / sum(atom_voxels),2))]) #normalizing pressure to cell size\n",
    "    #net pressure is each site's pressure coefficient weighted by the number of voxels it involves\n",
    "else:\n",
    "    data.append([\"Total\", \"undeterminable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f65e5892-0bee-42ab-a4d0-82c7509ae1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sysname = cif.split(\".\")[0] #file name\n",
    "qps = []\n",
    "qp_lmax = []\n",
    "qps_total = []\n",
    "qp_lines = [\"_\"*85+\"\\n\", \"  CP Quadrupole Report\\n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2106f8ef-a382-4cda-bc3e-46cb16b0d3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'CaFe4Sb12_Ca2Fe8Sb24' already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory name\n",
    "if sysname==full_formula:\n",
    "    directory_name=sysname\n",
    "else:\n",
    "    directory_name = sysname+\"_\"+full_formula\n",
    "\n",
    "# Create the directory\n",
    "try:\n",
    "    os.mkdir(directory_name)\n",
    "    print(f\"Directory '{directory_name}' created successfully.\")\n",
    "except FileExistsError:\n",
    "    print(f\"Directory '{directory_name}' already exists.\")\n",
    "except PermissionError:\n",
    "    print(f\"Permission denied: Unable to create '{directory_name}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f2330da9-34e3-4320-a284-d258ded5caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(coeffs)): #for each atom\n",
    "    qps.append([0,0,0,0,0])\n",
    "    for j in range(5):\n",
    "        for k in range(j**2,(j+1)**2): #an increasing odd number for each, as in the harmonics\n",
    "            qps[i][j] += coeffs[i][k]**2 #combining each level squared, for l=0 to 4 for each atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e1890e0f-244d-475a-9484-0bf2ea0a2d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(qps)): #for each atom\n",
    "    qp_lmax.append([0,0,0])\n",
    "    qps_total.append([])\n",
    "    for j in range(3):\n",
    "        for k in range(j+3):\n",
    "            qp_lmax[i][j] += qps[i][k] #summing the combined coeff values, starting with first 3, up to all.\n",
    "    for j in range(3):\n",
    "        try: \n",
    "            qps_total[i].append(qps[i][2]/qp_lmax[i][j]) #how much the l=2 level comb coeff (d basically) is of the total added coeffs, three here too, how quadrupolar it is\n",
    "        except:\n",
    "            qps_total[i].append(0)\n",
    "    for j in range(5):\n",
    "        try:\n",
    "            qps_total[i].append(qps[i][j]/qp_lmax[i][2]) #new, contribution of each\n",
    "        except:\n",
    "            qps_total[i].append(0)\n",
    "    try:\n",
    "        qps_total[i].append(coeffs[i][4]**2/qp_lmax[i][2]) #new, dz^2 contribution\n",
    "    except:\n",
    "        qps_total[i].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "33441fc9-7d4c-4ebf-b4c3-46f3313d9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(qps_total)): #for each atom\n",
    "    qp_lines.append(\"    Atom {0:3n} ({1:2s})    (2/2max): {2:.6f}  (2/3max): {3:.6f}  (2/4max): {4:.6f}  (l = 0): {5:.6f}  (l = 1): {6:.6f}  (l = 2): {7:.6f}  (l = 3): {8:.6f}  (l = 4): {9:.6f}  (z2): {10:.6f}\\n\".format(i+1, geo[i][0], qps_total[i][0], qps_total[i][1], qps_total[i][2],qps_total[i][3],qps_total[i][4],qps_total[i][5],qps_total[i][6],qps_total[i][7],qps_total[i][8]))\n",
    "#values here: atom number, element, l2 contribution to 0-2, 0-3, 0-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "42c89b2b-fad0-48f7-8e53-445d959c6bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qp_lines.append(\"_\"*85+\"\\n\") #formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7bd51815-3b91-4c29-beed-0ce18a38939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = [\"0p\", \"1p\", \"1m\", \"2p\", \"2m\", \"3p\", \"3m\", \"4p\", \"4m\", \"5p\", \"5m\", \"6p\", \"6m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6f89f4ac-e178-4647-b58b-82a69959649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_labels = [\"l_\"+str(i)+\"m_\"+pm[j]+\"=\" for i in range(7) for j in range(2*i+1)] #???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4a4cced-83ac-4fac-bcba-cdb87d985508",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_labels[0] = coeff_labels[0].replace(\"0p=\", \"0=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "afadc738-14cb-4b2b-868a-188ad0fc8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcell = \"\\n\".join([\"    \" + \"    \".join([\"{:.6f}\".format(j) for j in i]) for i in cell]) #cell dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fd2e8f2d-521d-4eaa-ad40-8981207667e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgeo = \"\\n\".join([\"      \".join([i[0]]+[\"{:.6f}\".format(j) for j in i[1:]]) for i in geo]) #atom positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "84fc6edc-f97f-4f92-9ab7-dd2754278694",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcoeffs = \"\\n\".join([\"\\n\".join([coeff_labels[j]+\"      {:.14f}\".format(i[j]) for j in range(len(i))]) for i in coeffs]) #labeled coeffs. these wrong???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "30814390-83fd-4f04-83aa-ed2c27cae963",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/aboth/Desktop/gordon/mlcpproject/mlcp code/'+directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "02dc4e5a-dd0c-4ed0-b469-4af0b18c3cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modifile(sysname+\"_MLCP-cell\", \"w\", pcell) #writes the files\n",
    "modifile(sysname+\"_MLCP-geo\", \"w\", pgeo)\n",
    "modifile(sysname+\"_MLCP-coeff\", \"w\", pcoeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "207f4e6e-3162-439b-bc82-31f3ed9a5572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(round(t2-t1,3))\\nprint(round(t3-t2,3))\\nprint(round(t4-t3,3))\\nprint(round(t5-t4,3))\\nprint(round(t6-t5,3))\\nprint(round(t7-t6,3))\\nprint(round(t7-t1,3))\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t7 = time.time()\n",
    "\n",
    "\"\"\"\n",
    "print(round(t2-t1,3))\n",
    "print(round(t3-t2,3))\n",
    "print(round(t4-t3,3))\n",
    "print(round(t5-t4,3))\n",
    "print(round(t6-t5,3))\n",
    "print(round(t7-t6,3))\n",
    "print(round(t7-t1,3))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "42c9385d-8d8a-4cfe-a7a2-85b79438ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(sysname+\"_MLCP-data\",\"w\") #the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3030c080-438f-411b-8965-391c226dde1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(\"Based on: \"+cif+\"\\nRan at Scale Factor: \"+str(sf)+\"\\n\") #adds the data/param info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b9851bd4-c7c9-46b0-a2f6-11b3de6171f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5cc87f29-49fc-480e-8daa-d584c63499cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Full Formula (Ca2 Fe8 Sb24)\n",
      "    Reduced Formula: Ca(FeSb3)4\n",
      "    abc   :   9.154000   9.154000   9.154000\n",
      "    angles:  90.000000  90.000000  90.000000\n"
     ]
    }
   ],
   "source": [
    "for i in summary: #more of the data things\n",
    "    print(\"   \",i)\n",
    "    f.write(i+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "055a6456-d766-4b74-913a-574b682bf548",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in qp_lines: #adding quadrupole report\n",
    "    f.write(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2e80b2ba-a2af-4ec0-a985-2e6bcfeb8c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ca :  -48.25 GPa\n",
      "    Ca :  -48.19 GPa\n",
      "    Fe :  68.35 GPa\n",
      "    Fe :  68.35 GPa\n",
      "    Fe :  68.35 GPa\n",
      "    Fe :  68.32 GPa\n",
      "    Fe :  68.32 GPa\n",
      "    Fe :  68.32 GPa\n",
      "    Fe :  68.32 GPa\n",
      "    Fe :  68.31 GPa\n",
      "    Sb :  -7.66 GPa\n",
      "    Sb :  -7.55 GPa\n",
      "    Sb :  -7.60 GPa\n",
      "    Sb :  -7.70 GPa\n",
      "    Sb :  -7.66 GPa\n",
      "    Sb :  -7.55 GPa\n",
      "    Sb :  -7.60 GPa\n",
      "    Sb :  -7.70 GPa\n",
      "    Sb :  -7.66 GPa\n",
      "    Sb :  -7.55 GPa\n",
      "    Sb :  -7.60 GPa\n",
      "    Sb :  -7.70 GPa\n",
      "    Sb :  -7.72 GPa\n",
      "    Sb :  -7.58 GPa\n",
      "    Sb :  -7.66 GPa\n",
      "    Sb :  -7.33 GPa\n",
      "    Sb :  -7.72 GPa\n",
      "    Sb :  -7.58 GPa\n",
      "    Sb :  -7.66 GPa\n",
      "    Sb :  -7.33 GPa\n",
      "    Sb :  -7.72 GPa\n",
      "    Sb :  -7.58 GPa\n",
      "    Sb :  -7.66 GPa\n",
      "    Sb :  -7.33 GPa\n",
      "    Total :  4.76 GPa\n"
     ]
    }
   ],
   "source": [
    "for i in data: #pressure data\n",
    "    print(\"   \", i[0], \": \", i[1])\n",
    "    f.write(i[0]+\": \"+i[1]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a1c66c-61d7-412f-b2be-209a3238a90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f0647bcf-fb5f-40b1-828b-be3af4d32dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total time: 5.17 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"    Total time:\", round(t7-t1, 2), \"sec.\")\n",
    "f.write(\"Total time: \"+str(round(t7-t1, 2))+\" sec.\\n\") #time report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2aba97e1-2348-4323-ace4-e775465c7501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f.close()\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cac17f48-fc4c-4abc-9834-648b80db2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/aboth/Desktop/gordon/mlcpproject/mlcp code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f62cd7fb-68dd-4738-bfde-0b54da8c01b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bptable_lines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ede4fc7e-9a17-4464-9232-968f2914fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bptable)):\n",
    "    bptable_lines.append(bptable[i][0]+\" \") #the first atom\n",
    "    for j in range(len(bptable[i][1])):\n",
    "        bptable_lines[i] += '{0:.6f} '.format(bptable[i][1][j]) #the coords\n",
    "    bptable_lines[i] += \"to \" + bptable[i][2] + \" \" #to the second atom \n",
    "    for j in range(len(bptable[i][3])):\n",
    "        bptable_lines[i] += '{0:.6f} '.format(bptable[i][3][j]) #at its coords\n",
    "    bptable_lines[i] += \"dist = {0:.6f}\".format(np.linalg.norm(bptable[i][1]-bptable[i][3])) #distance\n",
    "    bptable_lines[i] += \" pressure = {0:.6f} voxels: {1:.6f} volume of contact: {2:.6f}\\n\".format(bptable[i][4], bptable[i][5], bptable[i][6])\n",
    "# pressure, voxels, volume, added last 2 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9ba47f19-10ba-49b1-9d26-c5ddc8e6004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/aboth/Desktop/gordon/mlcpproject/mlcp code/'+directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d951dc0d-8baa-433a-a06b-100f4e4a1a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modifile(sysname+\"_MLCP-bptable\",\"w\",bptable_lines) #writing the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f596de21-6a18-438d-a80b-65eff5d82848",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/aboth/Desktop/gordon/mlcpproject/mlcp code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2038b0f9-fc24-4240-9c8f-ecfa96847b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "result={}\n",
    "result['CIFname']=cif[:-4]\n",
    "result['directory']=directory_name\n",
    "result['name']=structure.composition.reduced_formula\n",
    "result['elements']=stoich #the element identifier of each\n",
    "result['counts']=s_tot #cumulutaive total of each element, with some factor\n",
    "result['abc']=structure.lattice.abc\n",
    "result['cell']=cell\n",
    "result['e_data']=e_data\n",
    "result['totalCP']=float(data[-1][1][:-4])\n",
    "result['sites']=sitenames\n",
    "result['geo']=geo\n",
    "result['CP']=cpvalues #l=0\n",
    "result['neighbors']=neighbors\n",
    "result['contacts']=[row[0:2] for row in unique] #unique contacts\n",
    "result['rfrpredictions']=predictions_rfr #for each in unique contacts\n",
    "result['coeffs']=coeffs #coefficient outputs\n",
    "result['allvnn']=allvnn\n",
    "result['bptable']=bptable #values here: first atom/coords, second, ml-cp, number of points nearby, (half of) the volume of the contact taken up\n",
    "result['bptablekey']=bptableguide #indices of the first atom, and the number of the associated contact\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c8b54b-0625-4992-9f2e-f3e2d38bc43e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
